{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import absolute\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.layers import Dense\n",
    "from keras.regularizers import l2\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "release_data_output = pd.read_csv(\"../Data/Release_Wrangled_res.csv\")\n",
    "release_data_features =pd.read_csv(\"../Data/Release_Wrangled.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximum_absolute_scaling(df):\n",
    "    # copy the dataframe\n",
    "    df_scaled = df.copy()\n",
    "    # apply maximum absolute scaling\n",
    "    for column in df_scaled.columns:\n",
    "        df_scaled[column] = df_scaled[column]  / df_scaled[column].abs().max()\n",
    "    return df_scaled\n",
    "    \n",
    "# call the maximum_absolute_scaling function\n",
    "DF_x_scaled = maximum_absolute_scaling(release_data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "release_data_output = release_data_output['x'].map({2:1,1:0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_x_scaled = DF_x_scaled.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    1\n",
       "3    1\n",
       "4    0\n",
       "Name: x, dtype: int64"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "release_data_output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=24, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "DF_x_scaled, release_data_output, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1393/1393 [==============================] - 1s 824us/step - loss: 0.6555 - accuracy: 0.6397\n",
      "Epoch 2/10\n",
      "1393/1393 [==============================] - 1s 720us/step - loss: 0.6545 - accuracy: 0.6367\n",
      "Epoch 3/10\n",
      "1393/1393 [==============================] - 1s 709us/step - loss: 0.6507 - accuracy: 0.6431\n",
      "Epoch 4/10\n",
      "1393/1393 [==============================] - 1s 714us/step - loss: 0.6502 - accuracy: 0.6464\n",
      "Epoch 5/10\n",
      "1393/1393 [==============================] - 1s 721us/step - loss: 0.6480 - accuracy: 0.6444\n",
      "Epoch 6/10\n",
      "1393/1393 [==============================] - 1s 720us/step - loss: 0.6479 - accuracy: 0.6448\n",
      "Epoch 7/10\n",
      "1393/1393 [==============================] - 1s 745us/step - loss: 0.6500 - accuracy: 0.6416\n",
      "Epoch 8/10\n",
      "1393/1393 [==============================] - 1s 800us/step - loss: 0.6513 - accuracy: 0.6396\n",
      "Epoch 9/10\n",
      "1393/1393 [==============================] - 1s 727us/step - loss: 0.6493 - accuracy: 0.6449\n",
      "Epoch 10/10\n",
      "1393/1393 [==============================] - 1s 735us/step - loss: 0.6510 - accuracy: 0.6388\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14d406cd0>"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/215 [==============================] - 0s 563us/step - loss: 0.6490 - accuracy: 0.6433\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1024, input_dim=24, activation=tf.nn.relu))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(512, activation=tf.nn.relu))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(256,activation = tf.nn.relu, kernel_regularizer=keras.regularizers.l2(l=0.1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(128,activation = tf.nn.relu))\n",
    "model.add(Dense(1, activation=tf.nn.sigmoid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "DF_x_scaled, release_data_output, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "x_train, y_train, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "196/196 [==============================] - 3s 12ms/step - loss: 13.3783 - accuracy: 0.5872 - val_loss: 0.9293 - val_accuracy: 0.6453\n",
      "Epoch 2/10\n",
      "196/196 [==============================] - 2s 11ms/step - loss: 0.9348 - accuracy: 0.5942 - val_loss: 0.8409 - val_accuracy: 0.6453\n",
      "Epoch 3/10\n",
      "196/196 [==============================] - 2s 11ms/step - loss: 0.8585 - accuracy: 0.6171 - val_loss: 0.8008 - val_accuracy: 0.5724\n",
      "Epoch 4/10\n",
      "196/196 [==============================] - 2s 11ms/step - loss: 0.8031 - accuracy: 0.6279 - val_loss: 0.7650 - val_accuracy: 0.6453\n",
      "Epoch 5/10\n",
      "196/196 [==============================] - 2s 11ms/step - loss: 0.7728 - accuracy: 0.6204 - val_loss: 0.7592 - val_accuracy: 0.6453\n",
      "Epoch 6/10\n",
      "196/196 [==============================] - 2s 12ms/step - loss: 0.7530 - accuracy: 0.6363 - val_loss: 0.7443 - val_accuracy: 0.6424\n",
      "Epoch 7/10\n",
      "196/196 [==============================] - 2s 12ms/step - loss: 0.7446 - accuracy: 0.6353 - val_loss: 0.7270 - val_accuracy: 0.6453\n",
      "Epoch 8/10\n",
      "196/196 [==============================] - 2s 12ms/step - loss: 0.7280 - accuracy: 0.6303 - val_loss: 0.7138 - val_accuracy: 0.6453\n",
      "Epoch 9/10\n",
      "196/196 [==============================] - 2s 12ms/step - loss: 0.7266 - accuracy: 0.6340 - val_loss: 0.7173 - val_accuracy: 0.6453\n",
      "Epoch 10/10\n",
      "196/196 [==============================] - 2s 12ms/step - loss: 0.7115 - accuracy: 0.6436 - val_loss: 0.6978 - val_accuracy: 0.6453\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x161b6ea00>"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,validation_data = (x_val,y_val), epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6952 - accuracy: 0.6554\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
